<!-- Licensed under a BSD license. See license.html for license -->
<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
    <title>WebGL2 - load obj - cube</title>
    <style>
        body {
            margin: 0;
        }
        canvas {
            width: 100vw;
            height: 100vh;
            display: block;
        }
    </style>
</head>
<body>
</body>
<div>
    <canvas id="canvas"></canvas>
    <input id="u_refractiveIndex" type="range" min="1" max="10" step="0.0001" value="1.025" style="position:absolute;left:10px;top:10px;width:1600px;">
</div>
<script src="twgl.js/dist/4.x/twgl-full.min.js"></script>
<script src="resources/m4.js"></script>
<script>
    // WebGL2 - load obj - cube
    // from https://webgl2fundamentals.org/webgl/webgl-load-obj-cube.html

    "use strict";

    // This is not a full .obj parser.
    // see http://paulbourke.net/dataformats/obj/

    function parseOBJ(text) {
        // because indices are base 1 let's just fill in the 0th data
        const objPositions = [[0, 0, 0]];
        const objTexcoords = [[0, 0]];
        const objNormals = [[0, 0, 0]];

        // same order as `f` indices
        const objVertexData = [
            objPositions,
            objTexcoords,
            objNormals,
        ];

        // same order as `f` indices
        let webglVertexData = [
            [],   // positions
            [],   // texcoords
            [],   // normals
        ];

        function newGeometry() {
            // If there is an existing geometry and it's
            // not empty then start a new one.
            if (geometry && geometry.data.position.length) {
                geometry = undefined;
            }
            setGeometry();
        }

        function addVertex(vert) {
            const ptn = vert.split('/');
            ptn.forEach((objIndexStr, i) => {
                if (!objIndexStr) {
                    return;
                }
                const objIndex = parseInt(objIndexStr);
                const index = objIndex + (objIndex >= 0 ? 0 : objVertexData[i].length);
                webglVertexData[i].push(...objVertexData[i][index]);
            });
        }

        const keywords = {
            v(parts) {
                objPositions.push(parts.map(parseFloat));
            },
            vn(parts) {
                objNormals.push(parts.map(parseFloat));
            },
            vt(parts) {
                // should check for missing v and extra w?
                objTexcoords.push(parts.map(parseFloat));
            },
            f(parts) {
                const numTriangles = parts.length - 2;
                for (let tri = 0; tri < numTriangles; ++tri) {
                    addVertex(parts[0]);
                    addVertex(parts[tri + 1]);
                    addVertex(parts[tri + 2]);
                }
            },
        };

        const keywordRE = /(\w*)(?: )*(.*)/;
        const lines = text.split('\n');
        for (let lineNo = 0; lineNo < lines.length; ++lineNo) {
            const line = lines[lineNo].trim();
            if (line === '' || line.startsWith('#')) {
                continue;
            }
            const m = keywordRE.exec(line);
            if (!m) {
                continue;
            }
            const [, keyword, unparsedArgs] = m;
            const parts = line.split(/\s+/).slice(1);
            const handler = keywords[keyword];
            if (!handler) {
                console.warn('unhandled keyword:', keyword);  // eslint-disable-line no-console
                continue;
            }
            handler(parts, unparsedArgs);
        }

        return {
            position: webglVertexData[0],
            texcoord: webglVertexData[1],
            normal: webglVertexData[2],
        };
    }

    "use strict";

    var envmapVertexShaderSource = `#version 300 es

in vec4 a_position;
in vec3 a_normal;

uniform mat4 u_projection;
uniform mat4 u_view;
uniform mat4 u_world;

out vec3 v_worldPosition;
out vec3 v_worldNormal;

void main() {
  // Multiply the position by the matrix.
  gl_Position = u_projection * u_view * u_world * a_position;

  // send the view position to the fragment shader
  v_worldPosition = (u_world * a_position).xyz;

  // orient the normals and pass to the fragment shader
  v_worldNormal = mat3(u_world) * a_normal;
}
`;

    var envmapFragmentShaderSource = `#version 300 es
precision highp float;

// Passed in from the vertex shader.
in vec3 v_worldPosition;
in vec3 v_worldNormal;

// The texture.
uniform samplerCube u_texture;

// The position of the camera
uniform vec3 u_worldCameraPosition;

// The refractive index
uniform float u_refractiveIndex;

// we need to declare an output for the fragment shader
out vec4 outColor;

void main() {
  vec3 worldNormal = normalize(v_worldNormal);
  vec3 eyeToSurfaceDir = normalize(v_worldPosition - u_worldCameraPosition);

  vec3 refractedDirection = refract(eyeToSurfaceDir, worldNormal, 1.0 / u_refractiveIndex);
  vec3 reflectedDirection = reflect(eyeToSurfaceDir, worldNormal);

  float cosReflection = dot(worldNormal, normalize(reflectedDirection));
  float cosRefraction = dot(-worldNormal, normalize(refractedDirection));

  float Rs = abs((u_refractiveIndex * cosReflection - 1.0 * cosRefraction) / (u_refractiveIndex * cosReflection + 1.0 * cosRefraction));
  Rs = Rs * Rs;

  float Rp = abs((u_refractiveIndex * cosRefraction - 1.0 * cosReflection) / (u_refractiveIndex * cosRefraction + 1.0 * cosReflection));
  Rp = Rp * Rp;

  float Reff = 0.5 * (Rs + Rp);

  outColor = Reff * texture(u_texture, reflectedDirection) + (1.0 - Reff) * texture(u_texture, refractedDirection);
}
`;

    var skyboxVertexShaderSource = `#version 300 es
in vec4 a_position;
out vec4 v_position;
void main() {
  v_position = a_position;
  gl_Position = vec4(a_position.xy, 1, 1);
}
`;

    var skyboxFragmentShaderSource = `#version 300 es
precision highp float;

uniform samplerCube u_skybox;
uniform mat4 u_viewDirectionProjectionInverse;

in vec4 v_position;

// we need to declare an output for the fragment shader
out vec4 outColor;

void main() {
  vec4 t = u_viewDirectionProjectionInverse * v_position;
  outColor = texture(u_skybox, normalize(t.xyz / t.w));
}
`;

    async function main() {
        // Get A WebGL context
        /** @type {HTMLCanvasElement} */
        var canvas = document.querySelector("#canvas");
        var gl = canvas.getContext("webgl2");
        if (!gl) {
            return;
        }

        const SPEED = 7;
        var isMouseDown = false;
        var curX = 0.0;
        var curY = 0.0;
        var rotateX = 0.0;
        var rotateY = 0.0;

        // mouse
        function mousedown(event) {
            isMouseDown = true;
            curX = event.clientX;
            curY = event.clientY;
            event.preventDefault();
        }

        function mousemove(event) {
            if(isMouseDown) {
                var diffX = event.clientX - curX;
                var diffY = event.clientY - curY;
                rotateX += diffX / canvas.width * SPEED;
                rotateY += diffY / canvas.height * SPEED;
                rotateY = Math.min(rotateY, Math.PI / 2 - 0.001);
                rotateY = Math.max(rotateY, -Math.PI / 2 + 0.001);
                curX = event.clientX;
                curY = event.clientY;
            }
        }

        function mouseup(event) {
            isMouseDown = false;
        }

        canvas.onmousedown = mousedown;
        canvas.onmousemove = mousemove;
        document.onmouseup = mouseup;

        var zoomRate = 1.00;

        function zoom(event) {
            event.preventDefault();

            zoomRate += event.deltaY * -0.01;
        }
        canvas.onwheel = zoom;

        // Tell the twgl to match position with a_position, n
        // normal with a_normal etc..
        twgl.setAttributePrefix("a_");

        // Use twgl to compile the shaders and link into a program
        const envmapProgramInfo = twgl.createProgramInfo(
            gl, [envmapVertexShaderSource, envmapFragmentShaderSource]);
        const skyboxProgramInfo = twgl.createProgramInfo(
            gl, [skyboxVertexShaderSource, skyboxFragmentShaderSource]);

        // create sphere
        const response = await fetch('sphere_high.obj');
        const text = await response.text();
        const data = parseOBJ(text);

        // Because data is just named arrays like this
        //
        // {
        //   position: [...],
        //   texcoord: [...],
        //   normal: [...],
        // }
        //
        // and because those names match the attributes in our vertex
        // shader we can pass it directly into `createBufferInfoFromArrays`
        // from the article "less code more fun".

        // create a buffer for each array by calling
        // gl.createBuffer, gl.bindBuffer, gl.bufferData
        const sphereBufferInfo = twgl.createBufferInfoFromArrays(gl, data);
        // fills out a vertex array by calling gl.createVertexArray, gl.bindVertexArray
        // then gl.bindBuffer, gl.enableVertexAttribArray, and gl.vertexAttribPointer for each attribute
        const sphereVAO = twgl.createVAOFromBufferInfo(gl, envmapProgramInfo, sphereBufferInfo);


        // create buffers and fill with vertex data
        //const cubeBufferInfo = twgl.primitives.createCubeBufferInfo(gl, 1);
        const quadBufferInfo = twgl.primitives.createXYQuadBufferInfo(gl);

        //const cubeVAO = twgl.createVAOFromBufferInfo(gl, envmapProgramInfo, cubeBufferInfo);
        const quadVAO = twgl.createVAOFromBufferInfo(gl, skyboxProgramInfo, quadBufferInfo);

        // Create a texture.
        const texture = twgl.createTexture(gl, {
            target: gl.TEXTURE_CUBE_MAP,
            src: [
                'resources/images/computer-history-museum/pos-x.jpg',  /* webglfundamentals: url */
                'resources/images/computer-history-museum/neg-x.jpg',  /* webglfundamentals: url */
                'resources/images/computer-history-museum/pos-y.jpg',  /* webglfundamentals: url */
                'resources/images/computer-history-museum/neg-y.jpg',  /* webglfundamentals: url */
                'resources/images/computer-history-museum/pos-z.jpg',  /* webglfundamentals: url */
                'resources/images/computer-history-museum/neg-z.jpg',  /* webglfundamentals: url */
            ],
            min: gl.LINEAR_MIPMAP_LINEAR,
        });

        function degToRad(d) {
            return d * Math.PI / 180;
        }

        var fieldOfViewRadians = degToRad(60);

        requestAnimationFrame(drawScene);

        // Draw the scene.
        function drawScene(time) {
            // convert to seconds
            time *= 0.001;

            twgl.resizeCanvasToDisplaySize(gl.canvas);

            // Tell WebGL how to convert from clip space to pixels
            gl.viewport(0, 0, gl.canvas.width, gl.canvas.height);

            gl.enable(gl.CULL_FACE);
            gl.enable(gl.DEPTH_TEST);

            // Clear the canvas AND the depth buffer.
            gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);

            // Compute the projection matrix
            var aspect = gl.canvas.clientWidth / gl.canvas.clientHeight;
            var projectionMatrix =
                m4.perspective(fieldOfViewRadians, aspect, 1, 2000);

            // camera going in circle 2 units from origin looking at origin
            var YCoef = Math.cos(rotateY);
            var cameraPosition = [Math.cos(rotateX) * 4 * YCoef, Math.sin(rotateY) * 4, Math.sin(rotateX) * 4 * YCoef];
            var target = [0, 0, 0];
            var up = [0, 1, 0];
            // Compute the camera's matrix using look at.
            var cameraMatrix = m4.lookAt(cameraPosition, target, up);

            // Make a view matrix from the camera matrix.
            var viewMatrix = m4.inverse(cameraMatrix);

            // Rotate the cube around the x axis
            var worldMatrix = m4.scaling(zoomRate, zoomRate, zoomRate);

            // We only care about direction so remove the translation
            var viewDirectionMatrix = m4.copy(viewMatrix);
            viewDirectionMatrix[12] = 0;
            viewDirectionMatrix[13] = 0;
            viewDirectionMatrix[14] = 0;

            var viewDirectionProjectionMatrix = m4.multiply(
                projectionMatrix, viewDirectionMatrix);
            var viewDirectionProjectionInverseMatrix =
                m4.inverse(viewDirectionProjectionMatrix);

            // draw the sphere
            gl.depthFunc(gl.LESS);  // use the default depth test
            gl.useProgram(envmapProgramInfo.program);
            gl.bindVertexArray(sphereVAO);

            var refIndex = document.querySelector("#u_refractiveIndex");
            twgl.setUniforms(envmapProgramInfo, {
                u_world: worldMatrix,
                u_view: viewMatrix,
                u_projection: projectionMatrix,
                u_texture: texture,
                u_worldCameraPosition: cameraPosition,
                u_refractiveIndex: refIndex.value
            });
            twgl.drawBufferInfo(gl, sphereBufferInfo);

            // draw the skybox

            // let our quad pass the depth test at 1.0
            gl.depthFunc(gl.LEQUAL);

            gl.useProgram(skyboxProgramInfo.program);
            gl.bindVertexArray(quadVAO);
            twgl.setUniforms(skyboxProgramInfo, {
                u_viewDirectionProjectionInverse: viewDirectionProjectionInverseMatrix,
                u_skybox: texture,
            });
            twgl.drawBufferInfo(gl, quadBufferInfo);

            requestAnimationFrame(drawScene);
        }
    }

    main();
</script>
</html>
